{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Etivity_1_template.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/comaraDOTcom/100-days-of-code/blob/master/Etivity1/ET5003_Etivity1_CONOROMARA_20151845.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxK1_8f1dvrc"
      },
      "source": [
        "<div>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1vK33e_EqaHgBHcbRV_m38hx6IkG0blK_\" width=\"350\"/>\n",
        "</div> \n",
        "\n",
        "#**Artificial Intelligence - MSc**\n",
        "ET5003 - MACHINE LEARNING APPLICATIONS \n",
        "\n",
        "###Instructor: Enrique Naredo\n",
        "###ET5003_Etivity-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqXD_IwUQuBF",
        "cellView": "form"
      },
      "source": [
        "#@title Current Date\n",
        "Today = '2021-08-22' #@param {type:\"date\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzDKau31OjVO",
        "cellView": "form"
      },
      "source": [
        "#@markdown ---\n",
        "#@markdown ### Enter your details here:\n",
        "Student_ID = \"\" #@param {type:\"string\"}\n",
        "Student_full_name = \"\" #@param {type:\"string\"}\n",
        "#@markdown ---"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r39xGZckTpKx",
        "cellView": "form"
      },
      "source": [
        "#@title Notebook information\n",
        "Notebook_type = 'Example' #@param [\"Example\", \"Lab\", \"Practice\", \"Etivity\", \"Assignment\", \"Exam\"]\n",
        "Version = 'Draft' #@param [\"Draft\", \"Final\"] {type:\"raw\"}\n",
        "Submission = False #@param {type:\"boolean\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80m304lUefG4"
      },
      "source": [
        "## MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs8mHGcidHSa"
      },
      "source": [
        "\n",
        "\n",
        "The MNIST database  is a dataset of handwritten digits that has been and is extensively used in machine learning. There are $10$ classes, each image is $28\\times28$ pixels and, therefore, each input is $x_i\\in\\mathbb{R}^{784}$. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ailycCq5epj2"
      },
      "source": [
        "## Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-yNAxhUemjM"
      },
      "source": [
        "You have to extend the code to manage any arbitrary number of classes, in other words you have to implement a general-recipe multinomial logistic classifier and Bayesian multinomial logistic classifier.\n",
        "\n",
        "You must then select  3 digits at random and perform  the following task. \n",
        "\n",
        "1. Your goal is to use Bayesian multinomial logistic regression (as in the road-sign notebook) to solve this classification problem. \n",
        "\n",
        "2. You can downsize the training dataset (e.g., 40% training and 60%testing) if the computation of the posterior takes too much time in your computer.\n",
        "\n",
        "3. Use the posterior uncertainty to detect the instances (digits) in the test set that are hard to classify and remove them from the test-set.\n",
        "\n",
        "4. Then you need to compute again the accuracy of the general-recipe logistic regression on the remaining (non-difficult) instances and comment on the result.\n",
        "\n",
        "5. In practice, the task is to use uncertainty estimation to detect the difficult instances in the test-set. This is equivalent to refuse to classify all high-uncertainty instances or, in other words, when we are uncertain we say \"I don't know\" and we do not return any class. In this way, you will learn how uncertainty can be used to make safer decisions, by detecting the instances that are difficult to classify.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMRKRTQZe5fW"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxusAui7AX_f"
      },
      "source": [
        "# Suppressing Warnings:\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQOfGMQpdHSb"
      },
      "source": [
        "# Import libraries\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import scipy.optimize as optimize\n",
        "from scipy.special import erf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from skimage.io import imread, imshow\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "%matplotlib inline\n",
        "import arviz as az\n",
        "from scipy.io import loadmat\n",
        "import pymc3 as pm\n",
        "import random\n",
        "from IPython.display import HTML\n",
        "import pickle\n",
        "import theano as tt\n",
        "import cv2\n",
        "from sklearn.utils import shuffle\n",
        "from skimage.color import rgb2gray"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5-qMSjpAQ-9"
      },
      "source": [
        "# Setting a seed:\n",
        "np.random.seed(123)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4hSuwkUfVQb"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w99Pc66YdHSd"
      },
      "source": [
        "### Loading the MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYFWAbXVzynp",
        "outputId": "34e80374-9a12-4027-d4da-6b58f2d7ab4b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4rCnS4vdHSd",
        "outputId": "1f3d9525-aec9-4d62-d45b-53ab69d583a5"
      },
      "source": [
        "# Path, copy the path from your Drive\n",
        "#Path = '/content/drive/MyDrive/Colab Notebooks/Enrique/Data/'\n",
        "Path = '/content/drive/My Drive/Masters/ET5003_Enrique/etivity1/mnist-data/'\n",
        "\n",
        "# MNIST Data\n",
        "train_data = Path + 'mnist_train.csv'\n",
        "test_data = Path + 'mnist_test.csv'\n",
        "\n",
        "# train data\n",
        "df_train = pd.read_csv(train_data)\n",
        "X_train = df_train.drop(\"label\",axis=1).values\n",
        "y_train = df_train.label.values\n",
        "print(X_train.shape)\n",
        "\n",
        "# test data\n",
        "df_test = pd.read_csv(test_data)\n",
        "X_test = df_test.drop(\"label\",axis=1).values\n",
        "y_test = df_test.label.values\n",
        "print(X_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2ubJ_WoAqBh",
        "outputId": "09e010bb-9b62-40d8-e602-0dd38be13690"
      },
      "source": [
        "# Normalizing the Inputs:\n",
        "X_train = X_train/255\n",
        "X_test = X_test/255\n",
        "\n",
        "# Printing the new input range of values:\n",
        "minv = np.min(X_train)\n",
        "maxv = np.max(X_train)\n",
        "print(minv,maxv)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR6HpkWndHSe"
      },
      "source": [
        "### Description of Data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sibN1Vv1dHSf",
        "outputId": "de1137f5-a641-4820-f5ef-020933b346bb"
      },
      "source": [
        "# Number of examples\n",
        "n_train =  len(X_train)\n",
        "n_test =  len(X_test)\n",
        "\n",
        "# Shape of an traffic sign image\n",
        "image_shape = X_train.shape[1]\n",
        "\n",
        "# unique classes/labels in the training dataset.\n",
        "alltotal = set(y_train)\n",
        "n_classes = len(alltotal)\n",
        "\n",
        "print(\"Number of Training examples =\", n_train)\n",
        "print(\"Number of Test examples =\", n_test)\n",
        "print(\"Image input shape =\", image_shape)\n",
        "print(\"Number of classes =\", n_classes)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Training examples = 60000\n",
            "Number of Test examples = 10000\n",
            "Image input shape = 784\n",
            "Number of classes = 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HQDSvrRKZF6"
      },
      "source": [
        "### Class Distribution:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XG8GdlpBKdCt"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ind = np.arange(n_classes)\n",
        "\n",
        "n, bins, patches = ax.hist(y_train, n_classes)\n",
        "ax.set_xlabel('classes')\n",
        "ax.set_ylabel('counts')\n",
        "ax.set_title(r'Histogram of Digit images')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyLWw3nsLCtk"
      },
      "source": [
        "## Downsampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2U1lFEwhLKBf"
      },
      "source": [
        "### Randomly selecting 3 of the 10 Digit Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EeRZZWdLRPT"
      },
      "source": [
        "# We select the number of Classes we want:\n",
        "n_classes = \n",
        "\n",
        "# Empty list to append the random digit classes we select:\n",
        "classes = \n",
        "\n",
        "# We select 3 digits at random and make sure they are unique:\n",
        "while len(classes) < :\n",
        "    \n",
        "    # Randomly drawing a digit from 0-9:\n",
        "    num2choose = np.random.randint(0,10)\n",
        "\n",
        "    # Append the digit if it's not already in our list of classes:\n",
        "    if label not in classes: \n",
        "        classes.append(num2choose)\n",
        "        \n",
        "        \n",
        "# Sorting the Classes smallest to largest    \n",
        "classes.___\n",
        "# print classes selected\n",
        "classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M8R5NqKMB_M"
      },
      "source": [
        "# The number of instances we'll keep for each of our 3 digits:\n",
        "inst_class = \n",
        "\n",
        "\n",
        "# Loop to randomly sample the instances for each digit:\n",
        "for r in classes:\n",
        "    imgs = X_train[np.where(y_train==r)[0],:]\n",
        "    inputs.append(imgs[np.random.permutation(imgs.shape[0]),:][0:inst_class,:])\n",
        "    labels.append(np.ones(inst_class)*r)\n",
        "    \n",
        "# Shaping inputs and labels in the right format    \n",
        "X_train = np.vstack(inputs).astype(np.float64)\n",
        "y_train = np.hstack(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6-YHrQQMicy"
      },
      "source": [
        "New Classes Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RA300COaMxWm"
      },
      "source": [
        "# new histogram"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFgP4xugMvJm"
      },
      "source": [
        "# plot digits\n",
        "def plot_digits(instances, images_per_row=5, **options):\n",
        "    size = 28\n",
        "    images_per_row = min(len(instances), images_per_row)\n",
        "    images = [instance.reshape(size,size) for instance in instances]\n",
        "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
        "    row_images = []\n",
        "    n_empty = n_rows * images_per_row - len(instances)\n",
        "    images.append(np.zeros((size, size * n_empty)))\n",
        "    for row in range(n_rows):\n",
        "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
        "        row_images.append(np.concatenate(rimages, axis=1))\n",
        "    image = np.concatenate(row_images, axis=0)\n",
        "    plt.imshow(image,  cmap='gist_yarg', **options)\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeEG-LGOM4fJ"
      },
      "source": [
        "# Show a few instances from each Digit:\n",
        "plt.figure(figsize=(8,8))\n",
        "\n",
        "# Selecting a few label indices from each of the 3 classes to show:\n",
        "\n",
        "\n",
        "# Plotting 'original' image\n",
        "plot_digits(X_train[label_indices,:],images_per_row=9)\n",
        "plt.title(\"Original\", fontsize=14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsAOnOcNNG_V"
      },
      "source": [
        "###  Splitting the Training data into both Training and Validation Sets:\n",
        "\n",
        "- Although this is the Training set, we can still set aside some samples (for instance 20%) of the 1,500 instances we have for Model Validation purposes.\n",
        "\n",
        "\n",
        "- With that Validation Set, we can then select the amount of Uncertainty we are happy with from our Model to use out of sample on other unseen data.\n",
        "\n",
        "\n",
        "- We can then test out how well our decision performs on the Test Set that we put aside earlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdsmyVAtPXNn"
      },
      "source": [
        "### Split tha dataset in training and validation sets\n",
        "# choose the fraction of your validation data from the training set\n",
        "w = 0.20\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=w, random_state=0)\n",
        " \n",
        "# Shuffling the training instaces around to randomize the order of inputs to the model:\n",
        "X_train, y_train = shuffle(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXwJwP0iPxhi"
      },
      "source": [
        "# print shape of your validation and training set\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOroY1QoP8DY"
      },
      "source": [
        "### Encoding the Class labels for the Probabilistic ML Model:\n",
        "\n",
        "This is an example:\n",
        "\n",
        "- **[1,0,0]** for first digit\n",
        "- **[0,1,0]** for second digit\n",
        "- **[0,0,1]** for third digit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjUaqWTqQIcp"
      },
      "source": [
        "### General-Recipe ML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzgdivxfQNv5"
      },
      "source": [
        "# model\n",
        "model_log = \n",
        "\n",
        "# Classification:\n",
        "y_pred_log = \n",
        "y_pred_logi_prob = model_log.predict_proba(X_val)\n",
        "\n",
        "# Maybe taking the maximum probability \n",
        "# in any of the classes for each observation\n",
        "\n",
        "\n",
        "# Computing the Accuracy:\n",
        "accuracy_score(y_pred_log, y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uQG6JsOQxH5"
      },
      "source": [
        "### Probabilistic Multinomial Logistic Regression:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3jzczJzRAtT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irlmUNw7Q5YL"
      },
      "source": [
        "The Multinomial Logistic Regression has some parameters:\n",
        "\n",
        "- $\\alpha$, which is the intercept term:\n",
        "\n",
        "- $\\beta$, which is a vector of coefficients which give a weighting to the importance of each input feature:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1o7mbKWmRhz5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj6Uzc05Rhtr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MFH4gwlRhrB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNmJvYc4Rho7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXh5GXJsRhmr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcshsLOGRPrk"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTc4pYKGRR60"
      },
      "source": [
        "Populate this section with all of your findings and comments fron the discussion with your peers."
      ]
    }
  ]
}